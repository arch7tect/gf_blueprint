<?xml version="1.0" encoding="ASCII"?>
<etl:UserDefinedFunction xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:etl="http://www.neoflex.ru/meta/etl" name="HBASE_LOOKUP" code="class HBaseLookupUdfClass extends scala.Function3[String, String, Array[Byte], Seq[Array[Byte]]] with Serializable {&#xA;&#xA;    import org.apache.hadoop.hbase.HBaseConfiguration&#xA;    import org.apache.hadoop.hbase.TableName&#xA;    import org.apache.hadoop.hbase.client.ConnectionFactory&#xA;    import org.apache.hadoop.hbase.client.Get&#xA;    import org.apache.hadoop.hbase.util.Bytes&#xA;    import org.apache.hadoop.hbase.client.Connection&#xA;    import org.apache.hadoop.hbase.client.Table&#xA;    import org.slf4j.LoggerFactory&#xA;    &#xA;  @transient var connection = null: Connection&#xA;  @transient var tables = null: scala.collection.mutable.HashMap[String, Table]&#xA;  @transient lazy val logger = {LoggerFactory.getLogger(getClass)}&#xA;&#xA;  def apply(tableName: String, columnNames: String, key: Array[Byte]): Seq[Array[Byte]] = {&#xA;    val columns = columnNames.split(&quot;[,;]&quot;).map(_.split(&quot;[:.]&quot;).map(_.trim()))&#xA;    logger.info(&quot;key: &quot; + key.mkString(&quot;&quot;))&#xA;    logger.info(&quot;columns: [&quot; + columns.map(&quot;(&quot; + _.mkString(&quot;, &quot;) + &quot;)&quot;).mkString(&quot;; &quot;) + &quot;]&quot;)&#xA;    val table = getTable(tableName)&#xA;    val get = new Get(key)&#xA;    columns.foreach(c=>get.addColumn(Bytes.toBytes(c(0)), Bytes.toBytes(c(1))))&#xA;    val result = table.get(get)&#xA;    columns.map(c=>result.getValue(Bytes.toBytes(c(0)),Bytes.toBytes(c(1))))&#xA;  }&#xA;  &#xA;  private def getConnection(): Connection = {&#xA;      if (connection == null) {&#xA;        logger.info(&quot;new HBase connection&quot;)&#xA;        val config = HBaseConfiguration.create()&#xA;        connection = ConnectionFactory.createConnection(config)&#xA;      }&#xA;      connection&#xA;  }&#xA;&#xA;  private def getTable(tableName: String): Table = {&#xA;      if (tables == null) {&#xA;        tables = new scala.collection.mutable.HashMap[String, Table]&#xA;      }&#xA;      tables.getOrElseUpdate(tableName, {&#xA;          val parts = tableName.split(&quot;[.]&quot;, 2)&#xA;          val (schema, table) = if (parts.size == 2) {(parts(0), parts(1))} else {(&quot;default&quot;, parts(0))}&#xA;          logger.info(&quot;new Table: &quot; + schema + &quot;.&quot; + table)&#xA;          getConnection().getTable(TableName.valueOf(schema, table))&#xA;      })&#xA;  }&#xA;&#xA;  sys.ShutdownHookThread {&#xA;    logger.info(&quot;exiting&quot;)&#xA;    if (tables != null) {&#xA;        for ((tableName, table)&lt;-tables) {&#xA;            table.close()&#xA;        }&#xA;        tables = null&#xA;    }&#xA;    if (connection != null) {&#xA;        connection.close()&#xA;        connection = null&#xA;    }&#xA;  }&#xA;}&#xA;" className="HBaseLookupUdfClass " withParameters="false"/>
